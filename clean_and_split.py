import os
import shutil
import random
from collections import defaultdict

def clean_and_organize_dataset(source_dir, output_dir="dataset", train_ratio=0.8):
    """
    ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø© ÙˆØªÙ‚Ø³ÙŠÙ…Ù‡Ø§ Ø¥Ù„Ù‰ train/val
    """
    print("ğŸ§¹ Ø¨Ø¯Ø¡ ØªÙ†Ø¸ÙŠÙ ÙˆØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    print("="*60)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬
    train_dir = os.path.join(output_dir, 'train')
    val_dir = os.path.join(output_dir, 'val')
    
    # Ù…Ø³Ø­ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙˆØ¥Ø¹Ø§Ø¯Ø© Ø¥Ù†Ø´Ø§Ø¦Ù‡Ø§
    if os.path.exists(output_dir):
        print(f"ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯: {output_dir}")
        shutil.rmtree(output_dir)
    
    os.makedirs(train_dir, exist_ok=True)
    os.makedirs(val_dir, exist_ok=True)
    
    # Ø¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª (ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±)
    class_data = defaultdict(set)  # Ø§Ø³ØªØ®Ø¯Ø§Ù… set Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±
    
    print(f"ğŸ” ÙØ­Øµ Ø§Ù„Ù…Ø¬Ù„Ø¯: {source_dir}")
    
    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ©
    for root, dirs, files in os.walk(source_dir):
        folder_name = os.path.basename(root)
        
        # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙØ±Ø¹ÙŠØ© Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø©
        level = root.replace(source_dir, '').count(os.sep)
        if level > 2:
            continue
            
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ù‡Ø°Ø§ Ù…Ø¬Ù„Ø¯ ÙƒÙ„Ø§Ø³ (ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØµÙˆØ±)
        image_files = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        
        if image_files and folder_name != os.path.basename(source_dir):
            # ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„ÙƒÙ„Ø§Ø³
            class_name = clean_class_name(folder_name)
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙˆØ± Ù„Ù„ÙƒÙ„Ø§Ø³ (set ØªÙ…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±)
            for image_file in image_files:
                image_path = os.path.join(root, image_file)
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù ÙƒÙ…Ø¹Ø±Ù ÙØ±ÙŠØ¯ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±
                class_data[class_name].add((image_path, image_file))
    
    print(f"ğŸ“Š ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(class_data)} ÙƒÙ„Ø§Ø³:")
    
    total_train_images = 0
    total_val_images = 0
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ ÙƒÙ„Ø§Ø³
    for class_name, image_set in class_data.items():
        images_list = list(image_set)  # ØªØ­ÙˆÙŠÙ„ set Ø¥Ù„Ù‰ list
        num_images = len(images_list)
        
        print(f"  ğŸ“‚ {class_name}: {num_images} ØµÙˆØ±Ø©")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ÙƒÙ„Ø§Ø³
        train_class_dir = os.path.join(train_dir, class_name)
        val_class_dir = os.path.join(val_dir, class_name)
        
        os.makedirs(train_class_dir, exist_ok=True)
        os.makedirs(val_class_dir, exist_ok=True)
        
        # Ø®Ù„Ø· Ø§Ù„ØµÙˆØ± Ø¹Ø´ÙˆØ§Ø¦ÙŠØ§Ù‹
        random.shuffle(images_list)
        
        # ØªØ­Ø¯ÙŠØ¯ Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙ‚Ø³ÙŠÙ…
        split_point = int(num_images * train_ratio)
        
        # Ù†Ø³Ø® ØµÙˆØ± Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        train_images = images_list[:split_point]
        for i, (image_path, original_name) in enumerate(train_images):
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ù…Ù†Ø¸Ù…
            extension = os.path.splitext(original_name)[1]
            new_name = f"{class_name}_{i:04d}{extension}"
            dst_path = os.path.join(train_class_dir, new_name)
            
            try:
                shutil.copy2(image_path, dst_path)
            except Exception as e:
                print(f"    âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ù†Ø³Ø® {original_name}: {e}")
        
        # Ù†Ø³Ø® ØµÙˆØ± Ø§Ù„ØªÙ‚ÙŠÙŠÙ…  
        val_images = images_list[split_point:]
        for i, (image_path, original_name) in enumerate(val_images):
            extension = os.path.splitext(original_name)[1]
            new_name = f"{class_name}_val_{i:04d}{extension}"
            dst_path = os.path.join(val_class_dir, new_name)
            
            try:
                shutil.copy2(image_path, dst_path)
            except Exception as e:
                print(f"    âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ù†Ø³Ø® {original_name}: {e}")
        
        train_count = len(train_images)
        val_count = len(val_images)
        
        total_train_images += train_count
        total_val_images += val_count
        
        print(f"    âœ… ØªØ¯Ø±ÙŠØ¨: {train_count}, ØªÙ‚ÙŠÙŠÙ…: {val_count}")
    
    print(f"\nğŸ‰ ØªÙ… Ø§Ù„ØªÙ†Ø¸ÙŠÙ ÙˆØ§Ù„ØªÙ‚Ø³ÙŠÙ… Ø¨Ù†Ø¬Ø§Ø­!")
    print(f"ğŸ“ˆ Ø¥Ø¬Ù…Ø§Ù„ÙŠ ØµÙˆØ± Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {total_train_images}")
    print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ ØµÙˆØ± Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {total_val_images}")
    print(f"ğŸ“ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬: {output_dir}")
    
    # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª
    save_class_info(class_data.keys(), output_dir, total_train_images + total_val_images)
    
    return True

def clean_class_name(folder_name):
    """
    ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ù„ØªÙƒÙˆÙ† Ù…ÙˆØ­Ø¯Ø©
    """
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© ÙˆØ§Ù„Ø±Ù…ÙˆØ² Ø§Ù„ØºØ±ÙŠØ¨Ø©
    class_name = folder_name.strip()
    
    # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø®Ø§ØµØ©
    replacements = {
        '__': '___',  # ØªÙˆØ­ÙŠØ¯ Ø§Ù„ÙÙˆØ§ØµÙ„
        ' ': '_',     # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
        '(': '',      # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ù‚ÙˆØ§Ø³
        ')': '',
        ',': '',      # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙˆØ§ØµÙ„
    }
    
    for old, new in replacements.items():
        class_name = class_name.replace(old, new)
    
    return class_name

def save_class_info(class_names, output_dir, total_images):
    """
    Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª ÙÙŠ Ù…Ù„Ù
    """
    info_file = os.path.join(output_dir, 'dataset_info.txt')
    
    sorted_classes = sorted(class_names)
    
    with open(info_file, 'w', encoding='utf-8') as f:
        f.write("Plant Disease Dataset Information\n")
        f.write("="*50 + "\n\n")
        f.write(f"Total Classes: {len(sorted_classes)}\n")
        f.write(f"Total Images: {total_images}\n")
        f.write(f"Train/Val Split: 80%/20%\n\n")
        f.write("Classes List:\n")
        f.write("-"*30 + "\n")
        
        for i, class_name in enumerate(sorted_classes):
            plant, disease = parse_class_name(class_name)
            f.write(f"{i:2d}. {class_name}\n")
            f.write(f"    Plant: {plant}\n")
            f.write(f"    Disease: {disease}\n\n")
    
    # Ø­ÙØ¸ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ Ø§Ù„ÙƒÙˆØ¯
    classes_file = os.path.join(output_dir, 'class_names.txt')
    with open(classes_file, 'w', encoding='utf-8') as f:
        for class_name in sorted_classes:
            f.write(f"{class_name}\n")
    
    print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¯Ø§ØªØ§Ø³ÙŠØª ÙÙŠ:")
    print(f"    ğŸ“„ {info_file}")
    print(f"    ğŸ“„ {classes_file}")

def parse_class_name(class_name):
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù†Ø¨Ø§Øª ÙˆØ§Ù„Ù…Ø±Ø¶ Ù…Ù† Ø§Ø³Ù… Ø§Ù„ÙƒÙ„Ø§Ø³
    """
    if '___' in class_name:
        parts = class_name.split('___')
        plant = parts[0].replace('_', ' ').title()
        disease = parts[1].replace('_', ' ').title()
    else:
        parts = class_name.split('_')
        plant = parts[0].title()
        disease = ' '.join(parts[1:]).title() if len(parts) > 1 else 'Unknown'
    
    return plant, disease

def verify_dataset(dataset_dir):
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ØªÙ‚Ø³ÙŠÙ…
    """
    print(f"\nğŸ” Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ØªÙ‚Ø³ÙŠÙ… ÙÙŠ: {dataset_dir}")
    
    train_dir = os.path.join(dataset_dir, 'train')
    val_dir = os.path.join(dataset_dir, 'val')
    
    if not os.path.exists(train_dir) or not os.path.exists(val_dir):
        print("âŒ Ù…Ø¬Ù„Ø¯Ø§Øª train Ø£Ùˆ val ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©!")
        return False
    
    train_classes = set(os.listdir(train_dir))
    val_classes = set(os.listdir(val_dir))
    
    print(f"ğŸ“‚ ÙƒÙ„Ø§Ø³Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {len(train_classes)}")
    print(f"ğŸ“‚ ÙƒÙ„Ø§Ø³Ø§Øª Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {len(val_classes)}")
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª
    missing_in_val = train_classes - val_classes
    missing_in_train = val_classes - train_classes
    
    if missing_in_val:
        print(f"âš ï¸ ÙƒÙ„Ø§Ø³Ø§Øª Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ val: {missing_in_val}")
    
    if missing_in_train:
        print(f"âš ï¸ ÙƒÙ„Ø§Ø³Ø§Øª Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ train: {missing_in_train}")
    
    if not missing_in_val and not missing_in_train:
        print("âœ… Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙƒÙ„Ø§Ø³Ø§Øª Ù…ØªØ·Ø§Ø¨Ù‚Ø© ÙÙŠ train Ùˆ val")
        
        # Ø¹Ø¯ Ø§Ù„ØµÙˆØ± ÙÙŠ ÙƒÙ„ Ù…Ø¬Ù„Ø¯
        total_train = 0
        total_val = 0
        
        for class_name in train_classes:
            train_class_dir = os.path.join(train_dir, class_name)
            val_class_dir = os.path.join(val_dir, class_name)
            
            train_count = len([f for f in os.listdir(train_class_dir) 
                             if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
            val_count = len([f for f in os.listdir(val_class_dir) 
                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
            
            total_train += train_count
            total_val += val_count
        
        print(f"ğŸ“ˆ Ø¥Ø¬Ù…Ø§Ù„ÙŠ ØµÙˆØ± Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {total_train}")
        print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ ØµÙˆØ± Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {total_val}")
        print(f"ğŸ“ Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙ‚Ø³ÙŠÙ…: {total_train/(total_train+total_val)*100:.1f}% / {total_val/(total_train+total_val)*100:.1f}%")
        
        return True
    
    return False

if __name__ == "__main__":
    print("ğŸŒ± ØªÙ†Ø¸ÙŠÙ ÙˆØªÙ‚Ø³ÙŠÙ… Ø¨ÙŠØ§Ù†Ø§Øª Plant Disease")
    print("="*50)
    
    # Ù…Ø³Ø§Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠ
    source_path = r"data\dataset\PlantVillage"
    output_path = "dataset"
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø³Ø§Ø±
    if not os.path.exists(source_path):
        print(f"âŒ Ø§Ù„Ù…Ø³Ø§Ø± ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {source_path}")
        source_path = input("Ø£Ø¯Ø®Ù„ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­: ").strip()
        
        if not os.path.exists(source_path):
            print("âŒ Ø§Ù„Ù…Ø³Ø§Ø± ØºÙŠØ± ØµØ­ÙŠØ­!")
            exit()
    
    print(f"ğŸ“ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…ØµØ¯Ø±: {source_path}")
    print(f"ğŸ“ Ù…Ø³Ø§Ø± Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬: {output_path}")
    
    # Ø§Ù„Ø¨Ø¯Ø¡ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    success = clean_and_organize_dataset(source_path, output_path)
    
    if success:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø©
        verify_dataset(output_path)
        
        print(f"\nğŸš€ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:")
        print("1ï¸âƒ£ ØªØ´ØºÙŠÙ„: python train_model.py")
        print("2ï¸âƒ£ ØªØ´ØºÙŠÙ„: python app.py") 
        print("3ï¸âƒ£ ÙØªØ­: http://localhost:5000")
    else:
        print("âŒ ÙØ´Ù„ ÙÙŠ ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!")